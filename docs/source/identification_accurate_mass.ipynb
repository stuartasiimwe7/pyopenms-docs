{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification by Accurate Mass\n",
    "\n",
    "Example workflow for the processing of a set of `mzML` files (defined in\n",
    "the `files` variable) including centroiding, features detection,\n",
    ":term:feature: linking and accurate mass search. The resulting data gets\n",
    "processed in a pandas data frame with features filtering (missing\n",
    "values, quality) and imputation of remaining missing values. Compounds\n",
    "detected during accurate mass search will be annotated in the resulting\n",
    "dataframe.\n",
    "\n",
    "## Imports and `mzML` file path"
   ],
   "id": "9ee7cedf-98ab-4a53-b2db-61efa6349873"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "linenos": ""
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pyopenms import *\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set path to your mzML files, or leave like this to use the example data\n",
    "files = os.path.join(os.getcwd(), \"IdByMz_Example\")"
   ],
   "id": "bc2a92d2-d512-4421-81f2-56764af9f7ea"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Example Data\n",
    "\n",
    "Execute this cell only for the example workflow."
   ],
   "id": "5169a42b-0457-494b-8c79-262e91e0069f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "linenos": ""
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(os.path.join(os.getcwd(), \"IdByMz_Example\")):\n",
    "    os.mkdir(os.path.join(os.getcwd(), \"IdByMz_Example\"))\n",
    "\n",
    "base = \"https://abibuilder.cs.uni-tuebingen.de/archive/openms/Tutorials/Data/latest/Example_Data/Metabolomics/\"\n",
    "urls = [\n",
    "    \"datasets/2012_02_03_PStd_050_1.mzML\",\n",
    "    \"datasets/2012_02_03_PStd_050_2.mzML\",\n",
    "    \"datasets/2012_02_03_PStd_050_3.mzML\",\n",
    "    \"databases/PositiveAdducts.tsv\",\n",
    "    \"databases/NegativeAdducts.tsv\",\n",
    "    \"databases/HMDBMappingFile.tsv\",\n",
    "    \"databases/HMDB2StructMapping.tsv\",\n",
    "]\n",
    "\n",
    "for url in urls:\n",
    "    request = requests.get(base + url, allow_redirects=True)\n",
    "    open(os.path.join(files, os.path.basename(url)), \"wb\").write(\n",
    "        request.content\n",
    "    )"
   ],
   "id": "c545938a-08b6-4314-a94e-a04e3c9c0705"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centroiding\n",
    "\n",
    "If files are already centroided this step can bet omitted.\n",
    "\n",
    "`in`: path to MS data (files)\n",
    "\n",
    "`out`: path to centroided `mzML` files in a subfolder 'centroid' (files)"
   ],
   "id": "529dee32-028f-4e0d-bb06-9a2d209dd596"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "linenos": ""
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(files, \"centroid\")):\n",
    "    shutil.rmtree(os.path.join(files, \"centroid\"))\n",
    "os.mkdir(os.path.join(files, \"centroid\"))\n",
    "\n",
    "for file in os.listdir(files):\n",
    "    if file.endswith(\".mzML\"):\n",
    "        exp_raw = MSExperiment()\n",
    "        MzMLFile().load(os.path.join(files, file), exp_raw)\n",
    "        exp_centroid = MSExperiment()\n",
    "\n",
    "        PeakPickerHiRes().pickExperiment(exp_raw, exp_centroid, True)\n",
    "\n",
    "        MzMLFile().store(os.path.join(files, \"centroid\", file), exp_centroid)\n",
    "        del exp_raw\n",
    "\n",
    "files = os.path.join(files, \"centroid\")"
   ],
   "id": "845d3af6-e8d8-48ec-b996-6fcdff06cc19"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Detection\n",
    "\n",
    "`in`: path to centroid `mzML` files (files)\n",
    "\n",
    "`out`: list of :py`~.FeatureMap` (feature_maps)"
   ],
   "id": "c940ca87-bef9-4291-88e8-e74e077e13c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "linenos": ""
   },
   "outputs": [],
   "source": [
    "feature_maps = []\n",
    "\n",
    "for file in os.listdir(files):\n",
    "    if file.endswith(\".mzML\"):\n",
    "        exp = MSExperiment()\n",
    "        MzMLFile().load(os.path.join(files, file), exp)\n",
    "\n",
    "        exp.sortSpectra(True)\n",
    "\n",
    "        mass_traces = []\n",
    "        mtd = MassTraceDetection()\n",
    "        mtd_params = mtd.getDefaults()\n",
    "        mtd_params.setValue(\n",
    "            \"mass_error_ppm\", 5.0\n",
    "        )  # set according to your instrument mass error\n",
    "        mtd_params.setValue(\n",
    "            \"noise_threshold_int\", 1000.0\n",
    "        )  # adjust to noise level in your data\n",
    "        mtd.setParameters(mtd_params)\n",
    "        mtd.run(exp, mass_traces, 0)\n",
    "\n",
    "        mass_traces_split = []\n",
    "        mass_traces_final = []\n",
    "        epd = ElutionPeakDetection()\n",
    "        epd_params = epd.getDefaults()\n",
    "        epd_params.setValue(\"width_filtering\", \"fixed\")\n",
    "        epd.setParameters(epd_params)\n",
    "        epd.detectPeaks(mass_traces, mass_traces_split)\n",
    "\n",
    "        if epd.getParameters().getValue(\"width_filtering\") == \"auto\":\n",
    "            epd.filterByPeakWidth(mass_traces_split, mass_traces_final)\n",
    "        else:\n",
    "            mass_traces_final = mass_traces_split\n",
    "\n",
    "        feature_map = FeatureMap()\n",
    "        feat_chrom = []\n",
    "        ffm = FeatureFindingMetabo()\n",
    "        ffm_params = ffm.getDefaults()\n",
    "        ffm_params.setValue(\"isotope_filtering_model\", \"none\")\n",
    "        ffm_params.setValue(\n",
    "            \"remove_single_traces\", \"true\"\n",
    "        )  # set false to keep features with only one mass trace\n",
    "        ffm_params.setValue(\"mz_scoring_by_elements\", \"false\")\n",
    "        ffm_params.setValue(\"report_convex_hulls\", \"true\")\n",
    "        ffm.setParameters(ffm_params)\n",
    "        ffm.run(mass_traces_final, feature_map, feat_chrom)\n",
    "\n",
    "        feature_map.setUniqueIds()\n",
    "        feature_map.setPrimaryMSRunPath([file[:-5].encode()])\n",
    "\n",
    "        feature_maps.append(feature_map)"
   ],
   "id": "1cc15d86-f6fd-4409-bb1c-32d4e43c7044"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Map Retention Time Alignment\n",
    "\n",
    "`in`: unaligned list of :py`~.FeatureMap` (feature_maps)\n",
    "\n",
    "`out`: list of :py`~.FeatureMap` aligned to the first `feature map` in\n",
    "the list (feature_maps)"
   ],
   "id": "15d2ead8-941d-4f78-a587-7d62dedacdf4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "linenos": ""
   },
   "outputs": [],
   "source": [
    "# get in index of feature map with highest number of features in feature map list\n",
    "ref_index = [\n",
    "    i[0]\n",
    "    for i in sorted(\n",
    "        enumerate([fm.size() for fm in feature_maps]), key=lambda x: x[1]\n",
    "    )\n",
    "][-1]\n",
    "\n",
    "aligner = MapAlignmentAlgorithmPoseClustering()\n",
    "\n",
    "aligner.setReference(feature_maps[ref_index])\n",
    "\n",
    "for feature_map in feature_maps[:ref_index] + feature_maps[ref_index + 1 :]:\n",
    "    trafo = TransformationDescription()\n",
    "    aligner.align(feature_map, trafo)\n",
    "    transformer = MapAlignmentTransformer()\n",
    "    transformer.transformRetentionTimes(\n",
    "        feature_map, trafo, True\n",
    "    )  # store original RT as meta value"
   ],
   "id": "70c7b6e0-9ba5-4a3c-9b26-efd9f3f537cb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of RTs before and after Alignment"
   ],
   "id": "60ce82f6-7e79-422a-be5b-c7dfef5cdb31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "linenos": ""
   },
   "outputs": [],
   "source": [
    "fmaps = (\n",
    "    [feature_maps[ref_index]]\n",
    "    + feature_maps[:ref_index]\n",
    "    + feature_maps[ref_index + 1 :]\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.set_title(\"consensus map before alignment\")\n",
    "ax.set_ylabel(\"m/z\")\n",
    "ax.set_xlabel(\"RT\")\n",
    "\n",
    "# use alpha value to display feature intensity\n",
    "ax.scatter(\n",
    "    [f.getRT() for f in fmaps[0]],\n",
    "    [f.getMZ() for f in fmaps[0]],\n",
    "    alpha=np.asarray([f.getIntensity() for f in fmaps[0]])\n",
    "    / max([f.getIntensity() for f in fmaps[0]]),\n",
    ")\n",
    "\n",
    "for fm in fmaps[1:]:\n",
    "    ax.scatter(\n",
    "        [f.getMetaValue(\"original_RT\") for f in fm],\n",
    "        [f.getMZ() for f in fm],\n",
    "        alpha=np.asarray([f.getIntensity() for f in fm])\n",
    "        / max([f.getIntensity() for f in fm]),\n",
    "    )\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.set_title(\"consensus map after alignment\")\n",
    "ax.set_xlabel(\"RT\")\n",
    "\n",
    "for fm in fmaps:\n",
    "    ax.scatter(\n",
    "        [f.getRT() for f in fm],\n",
    "        [f.getMZ() for f in fm],\n",
    "        alpha=np.asarray([f.getIntensity() for f in fm])\n",
    "        / max([f.getIntensity() for f in fm]),\n",
    "    )\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.legend(\n",
    "    [fmap.getMetaValue(\"spectra_data\")[0].decode() for fmap in fmaps],\n",
    "    loc=\"lower center\",\n",
    ")\n",
    "# in some cases get file name elsewhere, e.g. fmap.getDataProcessing()[0].getMetaValue('parameter: out')\n",
    "fig.show()"
   ],
   "id": "7f3e4e45-ce27-482c-a908-c5e3730d30c9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Linking\n",
    "\n",
    "`in`: list of:py`~.FeatureMap` (feature_maps)\n",
    "\n",
    "`out`: :py`~.ConsensusMap` (consensus_map)"
   ],
   "id": "83eb6b74-9d16-4f54-9e49-7103e4678438"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "linenos": ""
   },
   "outputs": [],
   "source": [
    "feature_grouper = FeatureGroupingAlgorithmQT()\n",
    "\n",
    "consensus_map = ConsensusMap()\n",
    "file_descriptions = consensus_map.getColumnHeaders()\n",
    "\n",
    "for i, feature_map in enumerate(feature_maps):\n",
    "    file_description = file_descriptions.get(i, ColumnHeader())\n",
    "    file_description.filename = feature_map.getMetaValue(\"spectra_data\")[\n",
    "        0\n",
    "    ].decode()\n",
    "    file_description.size = feature_map.size()\n",
    "    file_description.unique_id = feature_map.getUniqueId()\n",
    "    file_descriptions[i] = file_description\n",
    "\n",
    "consensus_map.setColumnHeaders(file_descriptions)\n",
    "feature_grouper.group(feature_maps, consensus_map)"
   ],
   "id": "e8060196-8b7f-4980-928c-c31488e2a409"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConsensusMap to Pandas DataFrame\n",
    "\n",
    "`in`: :py`~.ConsensusMap` (consensus_map)\n",
    "\n",
    "`out`: DataFrame with RT, mz and quality from :py`~.ConsensusMap`\n",
    "(cm_df)"
   ],
   "id": "2694d923-23e8-4790-95c2-c0d468fc75f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "linenos": ""
   },
   "outputs": [],
   "source": [
    "intensities = consensus_map.get_intensity_df()\n",
    "\n",
    "meta_data = consensus_map.get_metadata_df()[[\"RT\", \"mz\", \"quality\"]]\n",
    "\n",
    "cm_df = pd.concat([meta_data, intensities], axis=1)\n",
    "cm_df.reset_index(drop=True, inplace=True)\n",
    "cm_df"
   ],
   "id": "694a7ac2-b8db-4833-a16c-75374418186b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accurate Mass Search\n",
    "\n",
    "`in`: :py`~.ConsensusMap` (consensus_map)\n",
    "\n",
    "`out`: DataFrame with :py`~.AccurateMassSearchEngine` results (ams_df)"
   ],
   "id": "f8b60068-db93-4f1c-852f-ab4abbab439e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "linenos": ""
   },
   "outputs": [],
   "source": [
    "if files.endswith(\"centroid\"):\n",
    "    files = os.path.join(files, \"..\")\n",
    "\n",
    "ams = AccurateMassSearchEngine()\n",
    "\n",
    "ams_params = ams.getParameters()\n",
    "ams_params.setValue(\"ionization_mode\", \"negative\")\n",
    "ams_params.setValue(\n",
    "    \"positive_adducts\", os.path.join(files, \"PositiveAdducts.tsv\")\n",
    ")\n",
    "ams_params.setValue(\n",
    "    \"negative_adducts\", os.path.join(files, \"NegativeAdducts.tsv\")\n",
    ")\n",
    "ams_params.setValue(\"db:mapping\", [os.path.join(files, \"HMDBMappingFile.tsv\")])\n",
    "ams_params.setValue(\n",
    "    \"db:struct\", [os.path.join(files, \"HMDB2StructMapping.tsv\")]\n",
    ")\n",
    "ams.setParameters(ams_params)\n",
    "\n",
    "mztab = MzTab()\n",
    "\n",
    "ams.init()\n",
    "\n",
    "ams.run(consensus_map, mztab)\n",
    "\n",
    "MzTabFile().store(os.path.join(files, \"ids.tsv\"), mztab)\n",
    "\n",
    "with open(os.path.join(files, \"ids_smsection.tsv\"), \"w\") as output, open(\n",
    "    os.path.join(files, \"ids.tsv\"), \"r\"\n",
    ") as input:\n",
    "    for line in input:\n",
    "        if line.lstrip().startswith(\"SM\"):\n",
    "            output.write(line[4:])\n",
    "\n",
    "ams_df = pd.read_csv(os.path.join(files, \"ids_smsection.tsv\"), sep=\"\\t\")\n",
    "\n",
    "os.remove(os.path.join(files, \"ids.tsv\"))\n",
    "os.remove(os.path.join(files, \"ids_smsection.tsv\"))\n",
    "\n",
    "ams_df"
   ],
   "id": "1a6b7714-2b7c-4920-890d-f691990fac9f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Filtering and Imputation\n",
    "\n",
    "`in`: unfiltered :py`~.ConsensusMap` DataFrame (cm_df)\n",
    "\n",
    "`out`: features below minimum quality and with too many missing values\n",
    "removed, remaining missing values imputed with KNN algorithm (cm_df)"
   ],
   "id": "71349ee5-5e74-445e-b711-3595349bd204"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "linenos": ""
   },
   "outputs": [],
   "source": [
    "allowed_missing_values = 1\n",
    "min_feature_quality = 0.8\n",
    "n_nearest_neighbours = 2\n",
    "\n",
    "# drop features that have more then the allowed number of missing values or are below minimum feature quality\n",
    "to_drop = []\n",
    "\n",
    "for i, row in cm_df.iterrows():\n",
    "    if (\n",
    "        row.isna().sum() > allowed_missing_values\n",
    "        or row[\"quality\"] < min_feature_quality\n",
    "    ):\n",
    "        to_drop.append(i)\n",
    "\n",
    "cm_df.drop(index=cm_df.index[to_drop], inplace=True)\n",
    "\n",
    "# Data imputation with KNN\n",
    "imputer = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", KNNImputer(n_neighbors=2)),\n",
    "        (\n",
    "            \"pandarizer\",\n",
    "            FunctionTransformer(\n",
    "                lambda x: pd.DataFrame(x, columns=cm_df.columns)\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cm_df = imputer.fit_transform(cm_df)\n",
    "cm_df"
   ],
   "id": "ed45acaa-6b55-4301-aed4-9bf6b30879ea"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate :term:Features\\<features\\><span class=\"title-ref\"> with\n",
    "Identified Compounds\n",
    "\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n",
    "</span><span class=\"title-ref\">in</span><span class=\"title-ref\">:\n",
    ":py:class:</span>\\~.ConsensusMap\\` DataFrame without identifications\n",
    "(cm_df) and :py`~.AccurateMassSearch` DataFrame (ams_df)\n",
    "\n",
    "`out`: :py`~.ConsensusMap` DataFrame with new identifications column\n",
    "(id_df)"
   ],
   "id": "dd8d920a-0076-4bf6-8335-3a39964a26f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "linenos": ""
   },
   "outputs": [],
   "source": [
    "id_df = cm_df\n",
    "\n",
    "id_df[\"identifications\"] = pd.Series([\"\" for x in range(len(id_df.index))])\n",
    "\n",
    "for rt, mz, description in zip(\n",
    "    ams_df[\"retention_time\"],\n",
    "    ams_df[\"exp_mass_to_charge\"],\n",
    "    ams_df[\"description\"],\n",
    "):\n",
    "    indices = id_df.index[\n",
    "        np.isclose(id_df[\"mz\"], float(mz), atol=1e-05)\n",
    "        & np.isclose(id_df[\"RT\"], float(rt), atol=1e-05)\n",
    "    ].tolist()\n",
    "    for index in indices:\n",
    "        if description != \"null\":\n",
    "            id_df.loc[index, \"identifications\"] += str(description) + \";\"\n",
    "id_df[\"identifications\"] = [\n",
    "    item[:-1] if \";\" in item else \"\" for item in id_df[\"identifications\"]\n",
    "]\n",
    "id_df.to_csv(os.path.join(files, \"result.tsv\"), sep=\"\\t\", index=False)\n",
    "id_df"
   ],
   "id": "388c8c21-bc15-4089-a5d0-dc8c9b8c0a2d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize `Consensus Features<consensus features>` with Identifications"
   ],
   "id": "13ec3f98-fd30-449b-82ab-87e56a862010"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "linenos": ""
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(id_df, x=\"RT\", y=\"mz\", hover_name=\"identifications\")\n",
    "fig.update_layout(title=\"Consensus features with identifications (hover)\")\n",
    "fig.show()"
   ],
   "id": "9810b096-297b-411b-99fc-63a53017991a"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
